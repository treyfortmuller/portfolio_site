---
layout: post
title:  "Lane Keeping RC Car"
date:   2019-03-01
excerpt: "LQR lane keeping controller and PID cruise control for a 1/10th scale vehicle, the Berkeley Autonomous Racecar (BARC)."
image: "/images/me131/barc.jpg"
---

## Introduction

During my final semester at Cal, I took ME131: Vehicle Dynamics and Control. The course focused on modeling automotive vehicle dynamics, understanding instabilities and safety implications, then building controllers to improve the vehicle behavior somehow. Modern cars have a slew of feedback control laws running at all times. We might segment all these controllers into two groups:

### 1. Low Level Controllers

Low level controllers augment the vehicle's dynamics to enhance safety or performance. They run at all times in normal passenger cars and they all work to ensure that the tires don't exceed their friction limits. These include:

* Anti-lock braking systems (ABS): modulates braking force to ensure the tires do not exceed their friction limits under maximum vehicle deceleration.
* Traction control: modulates engine torque to ensure the tires do not exceed their friction limits under maximum vehicle acceleration.
* Electronic stability control (ESP): is usually implemented as differential braking between the left and right wheels to control the yaw rate of the vehicle while turning.

<!-- MAYBE SOME MORE INFO ON TIRE FORCES AND THE NONLINEAR REGIME HERE WITH PLOTS -->

### 2. High Level Controllers

High level controllers relieve the driver of some part of the driving task. These controllers are meant to be a convenience to the driver, I've listed them in order of increasing sophistication and autonomony:

* Cruise control: modulates engine torque to maintain a desired reference speed.
* Adaptive cruise control: modulates engine torque and braking force to maintain a desired speed or following distance to the car ahead.
* Lane keep assist: actuates the car's steering to maintain a position inside the lane, often combined with adaptive cruise control for autonomous highway driving (such as the current state of Tesla's "autopilot").

The automotive world offers an extremely rich area of study for controls engineering, and now more than ever as ubiqitous sensors and compute find their way into modern vehicles. The massive effort for fully autonomous driving in the industry today makes automotive controls even more compelling. In ME131 I had the chance to derive and simulate vehicle dynamics in Matlab, then implement controllers I designed on a 1/10th scale RC car called the Berkeley Autonomous Racecar (BARC). Let's talk about the hardware first.

## The BARC

The BARC was developed by the [MPC Lab](http://www.mpc.berkeley.edu/) at UC Berkeley. It is a 1/10th scale, all-wheel-drive electric racecar.

### Powertrain

The vehicle is powered by a 2S, 8 Ah lithium-polymer battery. The drivetrain includes an electronic speed controller (ESC) which converts DC power from the battery to 3-phase AC for the brushless motor. The ESC also contains a 5V battery eliminator circuit (BEC) and serves as power distribution for the steering servo.

### Sensors

The BARC features an optical encoder on each wheel with eight counts per wheel revolution, allowing for an angular velocity estimate of each wheel. It also features a front facing digital camera which communicates data over serial to an ebedded Linux computer for processing at 30 frames per second. Color or intensity gradient thresholding on the image stream from the camera allows for edge detection within these frames, and thus for semantic data regarding relative position of the vehicle to a lane, to be extracted. The BARC also features an inertial measurement unit (IMU) consisting of an accelerometer and rate gyroscope for measurement of proper acceleration and angular rates of the vehicle. The IMU is not utilized in our lane keeping experiement.

### Compute

High level processes are handled by an Odroid XU4 embedded Linux computer running an image of Ubuntu Mate 16.04 maintained by the Berkeley MPC Lab. The Odroid has a 2Ghz ARM-based processor and 2Gb of DDR3 RAM making it a capable platform for soft real-time applications. The Odroid has several I/O ports and publishes a wifi access point for wireless communication with a host computer via secure shell (SSH) or virtual network computing (VNC). Low level processes are handled by an Arduino Nano microcontroller. This device reads sensor data and relays the data over serial to the Odroid. The microcontroller also receives control commands over serial from the Odroid and communicates via pulse width modulation (PWM) with the ESC. 

### Software

The Robot Operating System (ROS) is heavily used for inter-process communication onboard the BARC. ROS Kinetic is installed with the MPC lab's distribution of Ubuntu Mate 16.04 for the Odroid. Processes are segmented into nodes which publish and/or subscribe to topics on which messages of a given data structure are communicated. Often nodes are associated with hardware interfaces, data processing, controllers, estimators, etc. The data processing, estimators, and controllers for the lane keeping system are implemented in python leveraging several open source libraries including [OpenCV](https://opencv.org/) and [controlPy](https://github.com/markwmuller/controlpy).

## Approach and Methods

<!-- THESE PARAGRAPHS WONT MAKE ANY SENSE, CHANGE THESE -->

We use the lane detection code provided by the course staff but add several of our own scripts for data processing and control. We also modified the existing $$\texttt{low\_level\_PID\_controller.py}$$ to publish a vehicle longitudinal velocity estimate based on an average of encoder readings. Three of four encoders on our vehicle had reliable readings so we averaged their count rate as an input to the second order backwards finite difference method as a vehicle velocity estimate.

We added a script called $$\texttt{compute\_radius.py}$$ which subscribed to the $$\texttt{reference\_trajectory}$$ topic and computed the radius of curvature of the track ahead as an input the LQR controller. Seven x-y points in the body-fixed frame of the vehicle are returned by the lane detection system. The first point (closest to the vehicle's center of mass), and last point (furthest ahead of the vehicle), and the center point between them were used in the radius computation described in the Lab 10 documentation.

Finally, we added an $$\texttt{LQR\_synth.py}$$ script which subscribes to the track radius, vehicle velocity estimate, the ECU steering command, and the loop time $$dt$$ to compute a discrete LQR gain matrix on each loop, then output the controller's velocity and steering angle commands to the $$\texttt{/uOpt}$$ topic. The $$\texttt{rqt\_graph}$$ of the nodes and topics running on our system is shown below.

<!-- RQT GRAPH GOES HERE -->
{% include img_main.html path='/images/me131/rqt_graph.png' %}

We choose the nonlinear kinematic bicycle model of the vehicle as means to determine the optimal gain. The Jacobian linearization of these dynamics are computed as state transition matrices for our LQR gain matrix calculation, which is performed with the controlPy library. The control must be able to handle non-static setpoints so we choose a reference tracking LQR controller which brings the error between estimated and reference states to zero. We also include a feedforward term computed directly by the kinematic bicycle model. The full gain scheduled, reference tracking LQR lane keeping controller with feedforward can be represented as

<!-- HOW DO I PUT MATH IN THESE THINGS??? -->

$$ u(t) = -K(t)\cdot(z(t) - z_{ref}(t)) + u_{ref}(t) $$

Where $$K(t)$$ is the time varying LQR gain matrix, $$z(t) - z_{ref}(t)$$ is the state error, and $$u_{ref}(t)$$ is the feedforward term from the kinematic bicycle model.

## Results

After having implemented all the nodes necessary for our system, we ran into issues that made it difficult to debug our controller related to lane detection. After moving to a driving space with a homogeneous, non-reflective floor, we had success detecting lanes robustly with with our vehicle. An image of the lane detection and reference trajectory is shown below.

<!-- VNC VIEWER IMAGE GOES HERE -->
{% include img_main.html path='/images/me131/lane_detect.png' %}

We found our controller to be overactuating with the LQR cost matrices as identities. We lowered the Q matrix's cost by three orders of magnitude to avoid penalizing errors in the states so heavily. This improved the robustness of the tracking but, as expected, caused some extra variation away from the centerline on average. Upon increasing the reference velocity to 1 m/s, we saw reduced noise in the centerline trajectory and smoother driving. This performance is demonstrated in the video below.

{% include youtube.html url='https://www.youtube.com/embed/7w4f1qW-Uts' %}

### Discussion

<!-- NEED TO SHIFT THE TONE OF THESE PARAGRAPHS A BIT -->

The problem of autonomous navigation is hard because it consists of several sub-problems which are difficult in their own right, and solutions to these problems must work in harmony to deliver a robust system. Perception, trajectory generation, and control modules must deliver simultaneously for reliable driving. Our system focused on the control aspects of the problem, and thus shortcuts were taken in the perception and trajectory generation steps which lead to most of the issues we debugged after implementing our algorithms. The lane localization system used a simple edge detection algorithm based on finding intensity gradients greater than a hard coded threshold. This approach is not robust to changes in lighting, texture, or reflectance of the driving surface. Our vehicle struggled to reliably find lanes on shiny floors so we found a large space with dark carpeting and used bright white tape as lane lines for maximum contrast which improved tracking performance.

Another issue we struggled with throughout the project was wireless connectivity and lag while using VNC to connect to the Odroid to start nodes and view camera images. The next generation BARC vehicle should feature higher bandwidth, 5.8Ghz wireless connectivity. If nodes for image transmission over ROS were included in the BARC libraries and local machines were configured to communicate via ROS over the network then all of the debugging could take place with SSH alone. This would prevent the wasted overhead of a full virtual desktop which is slow and unreliable.

My code for the project is available on [Github](https://github.com/treyfortmuller/me131).

# Notes

## Labs

1. Nothing really (using the terminal and stuff)
2. (Simulating Kinematic Models in ROS) ROS intro, Github, integrating a ROS teleoperation node, PID cruise controller in simulation and tested response with the BARC simulator
3. (Introduction to the BARC Vehicle) Sending simple control commands mostly
4. (BARC System Identification) Least squares method and data collection to characterize PWM > accel and PWM > braking and PWM > steering transfer functions
5. (Longitudinal Dynamics: Cruise Control) PI Cruise Controller on the BARC (as opposed to simulation in Lab 2) Simulink experiment for gains via pole placement, then manual tuning on the vehicle
6. (Longitudinal Dynamics: Model-based Cruise Control) Coast down tests to determine Cd and Rx for the BARC (as we did for a simulated vehicle in HW3??) LQR cruise controller design, only done in Simulink experiment, not implemented on the car (**yet?**)
7. (Reconstructing Motion from IMU Data) Use real IMU data off of a car to reconstruct the motion comparing to GPS data as ground truth
8. (Lateral Control: Model-based) Comparing Kinematic Bicycle Model and Dynamic Bicycle Model open-loop predictions of motion given the longitudinal velocity Vx and df the steering input comapred to dGPS data off a real car as ground truth
9. (Implementing Lateral Control: Simulink) ---I'm here now---

# Outline

### Intro to BARC
It's capabilities, sensors, parts, who built it, how do you work with it (embedded linux computer and a ROS based software architecture), BARC github and website, how's I get my hands on one (taking a class in vehicle dynamics and control).

### Parameter Estimation
What paramaters do we need, what experiements can we do to get them, what infrastructure will we use to collect and process data, results from these experiements, might include actuator characterization, then Rx and Cd from the longitudinal model

### Controller Design
Models, simulation (using simulink or the BARC simulator), implementation, performance and results, videos

<!-- The _includes for images and videos -->
<!--
{% include img_main.html path='/images/e-board/motor_math.png' %}
{% include img_right.html path='/images/e-board/motor_math.png' %}
{% include img_left.html path='/images/e-board/motor_math.png' %}
{% include img_three.html left='/images/e-board/motor_math.png' center='/images/e-board/tx_rend2.png' right='/images/e-board/tx_rend3.png' %}
{% include youtube.html url='https://www.youtube.com/embed/KJxlBvzlVTY?rel=0' %}
-->

<!-- MathJax -->
<!--
Here is inline math $$ \psi = 1 $$.
Displayed math must be on its own paragraph.

$$ x = \int \dot{x} dt $$
-->